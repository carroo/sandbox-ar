<html>

<head>
    <!-- import aframe and then ar.js with image tracking / location based features -->
    <script
        src="https://cdn.jsdelivr.net/gh/aframevr/aframe@3f0df33946cf12e3d552b3b4e500dd5b8ff6f692/dist/aframe-master.min.js"></script>
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>

    <!-- style for the loader -->
    <style>
        .arjs-loader {
            height: 100%;
            width: 100%;
            position: absolute;
            top: 0;
            left: 0;
            background-color: rgba(0, 0, 0, 0.8);
            z-index: 9999;
            display: flex;
            justify-content: center;
            align-items: center;
        }
    </style>
</head>


<body style="margin : 0px; overflow: hidden;">
    <!-- minimal loader shown until image descriptors are loaded. Loading may take a while according to the device computational power -->
    <div class="arjs-loader">
        <div>Loading, please wait...</div>
    </div>

    <!-- a-frame scene -->
    <a-scene vr-mode-ui="enabled: false;" renderer="logarithmicDepthBuffer: true;" embedded
        arjs="trackingMethod: best; sourceType: webcam;debugUIEnabled: false;">
        <!-- a-nft is the anchor that defines an Image Tracking entity -->
        <!-- on 'url' use the path to the Image Descriptors created before. -->
        <!-- the path should end with the name without the extension e.g. if file is 'pinball.fset' the path should end with 'pinball' -->
        <a-nft type="nft" url="profile-pic" smooth="true" smoothCount="10" smoothTolerance=".01" smoothThreshold="5">
            <!-- as a child of the a-nft entity, you can define the content to show. here's a GLTF model entity -->

            <a-box color="red" scale="2 2 2" position="0 0 0"></a-box>
        </a-nft>
        <!-- static camera that moves according to the device movemenents -->
        <a-entity camera></a-entity>
    </a-scene>
</body>

</html>